{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages for entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3, json, re, datetime, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.dates as mdates\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = json.load(open('stopwords.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Messages database using Sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/Users/Brienna/Library/Messages/chat.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let user identify which handle_id to analyze**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View headings in the Messages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('select * from message')\n",
    "c.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the rowid, text, is_from_me, and datetime columns, placing into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd1 = 'SELECT ROWID, text, is_from_me, \\\n",
    "        datetime(date + strftime(\\'%s\\',\\'2001-01-01\\'), \\'unixepoch\\') as date_utc \\\n",
    "        FROM message WHERE handle_id=47'\n",
    "c.execute(cmd1)\n",
    "df_msg = pd.DataFrame(c.fetchall(), columns=['id', 'text', 'is_from_me', 'time'])\n",
    "df_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert datatime to something useable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msg['time'] = [datetime.datetime.strptime(str(t), '%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=-4) for t in df_msg['time']]\n",
    "df_msg['new_date'] = [d.date() for d in df_msg['time']]\n",
    "df_msg['new_time'] = [d.time() for d in df_msg['time']]\n",
    "df_msg['new_hours'] = [d.hour for d in df_msg['time']]\n",
    "df_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long the conversation has been going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = df_msg['new_date'].iloc[0]\n",
    "end = df_msg['new_date'].iloc[-1]\n",
    "print('from ' + str(start) + ' until ' + str(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total messages sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(df_msg)\n",
    "by_me = len(df_msg[df_msg['is_from_me'] == 1])\n",
    "by_himher = total - by_me\n",
    "print('Total: ' + str(total))\n",
    "print('From me: ' + str(by_me))\n",
    "print('From him/her: ' + str(by_himher))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = {}\n",
    "for message in df_msg['text']:\n",
    "    if message != None:\n",
    "        words = message.split(\" \")\n",
    "        for word in words:\n",
    "            word = re.sub(r'[^\\w\\s]','', word).lower().strip()\n",
    "            if word not in stopwords and word != '':\n",
    "                if word in frequencies:\n",
    "                    frequencies[word] += 1\n",
    "                else:\n",
    "                    frequencies[word] = 1\n",
    "\n",
    "frequencies_sorted = sorted(frequencies.items(), key=lambda kv: kv[1])\n",
    "print(frequencies_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most active day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mostCommon(lst):\n",
    "    data = Counter(lst)\n",
    "    return max(lst, key=data.get)\n",
    "\n",
    "most_common_day = mostCommon(list(df_msg['new_date']))\n",
    "print(most_common_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of texts on that day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_on_the_most_active_day = df_msg[df_msg['new_date'] == most_common_day]\n",
    "num_of_texts = len(df_on_the_most_active_day)\n",
    "num_of_texts_from_me = len(df_on_the_most_active_day[df_msg['is_from_me'] == 1])\n",
    "num_of_texts_from_himher = num_of_texts - num_of_texts_from_me\n",
    "\n",
    "print('Total texts sent on ' + str(most_common_day) + ' was ' + str(num_of_texts))\n",
    "print('From me: ' + str(num_of_texts_from_me))\n",
    "print('From him/her: ' + str(num_of_texts_from_himher))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average messages per day that we texted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_total = 0;\n",
    "distinct_days = 0;\n",
    "last_day_tracked = None;\n",
    "\n",
    "for index, row in df_msg.iterrows():\n",
    "    message = row['text']\n",
    "    if message != None:\n",
    "        messages_total += 1\n",
    "        current_day = row['new_date']\n",
    "        if last_day_tracked != current_day: \n",
    "            distinct_days += 1\n",
    "        last_day_tracked = current_day\n",
    "            \n",
    "print('Sent ' + str(math.floor(messages_total / distinct_days)) + ' messages on average each day.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create radar/spider plot showing average daily activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data frames\n",
    "\n",
    "df_24hrs_me = df_msg[df_msg['is_from_me'] == 1]['new_hours']\n",
    "df_24hrs_himher = df_msg[df_msg['is_from_me'] == 0]['new_hours']\n",
    "values_me = df_24hrs_me.value_counts().sort_index().values.flatten().tolist() # IMPORTANT TO SORT HOURS\n",
    "values_himher = df_24hrs_himher.value_counts().sort_index().values.flatten().tolist() # IMPORTANT TO SORT HOURS\n",
    "\n",
    "# We need to repeat the first value to close the circular graph:\n",
    "values_me += values_me[:1]\n",
    "values_himher += values_himher[:1]\n",
    "\n",
    "# Get number of variables\n",
    "categories = set(list(df_msg['new_hours'])[1:]) # set() reduces to distinct values\n",
    "N = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set angle of each axis in the plot (again repeating first value to close the circular graph)\n",
    "angles = [n / float(N) * 2 * math.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Initialize spider plot\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "## If you want the first axis to be on top\n",
    "ax.set_theta_offset(math.pi/2)\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "# Draw one axe per variable + add labels \n",
    "plt.xticks(angles[:-1], categories, color='grey', size=8);\n",
    "\n",
    "# Draw ylabels\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks([1000,2000,3000,4000,5000,6000], [\"1k\", \"2k\", \"3k\",\"4k\",\"5k\",\"6k\"], color='grey', size=8)\n",
    "plt.ylim(0,max(values_me))\n",
    "\n",
    "## ----------- Plot Individual 1 :: me\n",
    "ax.plot(angles, values_me, linewidth=1, linestyle='solid')\n",
    "ax.fill(angles, values_me, 'b', alpha=0.1);\n",
    " \n",
    "## ----------- Plot Individual 2 :: himher\n",
    "ax.plot(angles, values_himher, linewidth=1, linestyle='solid')\n",
    "ax.fill(angles, values_himher, 'r', alpha=0.1)\n",
    "\n",
    "red_patch = mpatches.Patch(color='r', label='Him',alpha=0.1)\n",
    "blue_patch = mpatches.Patch(color='b', label='Me',alpha=0.1)\n",
    "plt.legend(handles=[red_patch, blue_patch],loc='upper right', bbox_to_anchor=(0.1,0.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First occurrence of \"I love you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msg[df_msg['text'].str.contains('i love you', case=False) == True].sort_values(by='time').head(10)\n",
    "\n",
    "\n",
    "# idxmax shows first index value by condition, only necessitates that index is unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative query to avoid cases like \"I love your wordplay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "love_tests = pd.Series(['I love you', 'I love your wordplay']) # I don't really have other instances rn\n",
    "love_tests.str.contains(r'i love you\\b.*', case=False)\n",
    "ilys = df_msg[df_msg['text'].str.contains(r'i love you\\b.*', case=False) == True].sort_values(by='time')\n",
    "print('Said \"I love you\" ' + str(len(ilys)) + ' times')\n",
    "ilys.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual texts:\n",
    "print(df_msg.iloc[54171].text)\n",
    "print(df_msg.iloc[54172].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_week = df_msg.groupby(pd.Grouper(key='time', freq='W-MON')).count()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 10)\n",
    "plt.plot(messages_week.text, label='messages', color='pink') # the 200 is where on y axis the arrow points to\n",
    "\n",
    "fig.suptitle('Weekly message overview', fontsize=20)\n",
    "plt.xlabel('Weeks', fontsize=18)\n",
    "plt.ylabel('Messages', fontsize=18)\n",
    "plt.annotate('Ireland', (mdates.date2num(datetime.datetime(2018, 3, 15)), 200), xytext=(-100,0), \n",
    "            textcoords='offset points', size=20,\n",
    "            va='center', ha='center',\n",
    "            arrowprops=dict(arrowstyle=\"->\",\n",
    "                           connectionstyle='arc3, rad=-0.2',\n",
    "                           lw=2),\n",
    "            )\n",
    "plt.annotate('Bri in DC', (mdates.date2num(datetime.datetime(2018, 8, 28)), 205), xytext=(50, -50),\n",
    "            textcoords='offset points', size=20,\n",
    "            va='center', ha='center',\n",
    "            arrowprops=dict(arrowstyle=\"->\", lw=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NATURAL LANGUAGE PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/guiem/my_notebooks/blob/master/anniversary/anniversary.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate word cloud (needs stopwords and fixing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullTexts = \"\"\n",
    "for message in df_msg['text']:\n",
    "    if message != None:\n",
    "        fullTexts += message.lower()\n",
    "\n",
    "def generate_wordcloud(text):\n",
    "    wordcloud = WordCloud(font_path = '/Library/Fonts/Verdana.ttf',\n",
    "                         relative_scaling = 1.0).generate(text)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "generate_wordcloud(fullTexts)\n",
    "\n",
    "df_with_text = df_msg.text_normalized.dropna()\n",
    "top_1000 = pd.Series(' '.join(df_with_text).split()).value_counts()[:1000]\n",
    "wc = WordCloud(background_color='white')\n",
    "wc.generate_from_frequencies(list(top_1000).to_dict().items())\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

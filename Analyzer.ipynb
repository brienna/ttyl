{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages for entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sqlite3, json, re, datetime, math, emoji, matplotlib, calmap\n",
    "print(matplotlib.get_backend())\n",
    "import mplcairo\n",
    "matplotlib.use(\"module://mplcairo.macosx\")\n",
    "print(matplotlib.get_backend())\n",
    "print(mplcairo._mplcairo.__cairo_version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopwords = json.load(open('stopwords.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Messages database using Sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/Users/Brienna/Library/Messages/chat.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(c.execute('select * from message_attachment_join').description)\n",
    "cmd1 = 'SELECT * FROM chat'\n",
    "c.execute(cmd1)\n",
    "deleted_msg = pd.DataFrame(c.fetchall(), columns=['ROWID', 'guid', 'style', 'state', 'account_id', 'properties','chat_identifier','service_name','room_name','account_login','is_archived','last_addressed_handle','display_name','group_id','is_filtered','successful_query'])\n",
    "deleted_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let user identify which handle_id to analyze**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View headings in the Messages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c.execute('select * from message')\n",
    "headings = [description[0] for description in c.description]\n",
    "headings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the rowid, text, is_from_me, and datetime columns, placing into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmd1 = 'SELECT ROWID, text, is_from_me, \\\n",
    "        datetime(date + strftime(\\'%s\\',\\'2001-01-01\\'), \\'unixepoch\\') as date_utc \\\n",
    "        FROM message WHERE handle_id=47 OR handle_id=56 OR handle_id=90'\n",
    "c.execute(cmd1)\n",
    "df_msg = pd.DataFrame(c.fetchall(), columns=['id', 'text', 'is_from_me', 'time']).sort_values(by='time')\n",
    "df_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert datatime to something useable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_msg['time'] = [datetime.datetime.strptime(str(t), '%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=-4) for t in df_msg['time']]\n",
    "df_msg['new_date'] = [d.date() for d in df_msg['time']]\n",
    "df_msg['new_time'] = [d.time() for d in df_msg['time']]\n",
    "df_msg['new_hours'] = [d.hour for d in df_msg['time']]\n",
    "df_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long the conversation has been going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = df_msg['new_date'].iloc[0]\n",
    "end = df_msg['new_date'].iloc[-1]\n",
    "print('from ' + str(start) + ' until ' + str(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total messages sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total = len(df_msg)\n",
    "by_me = len(df_msg[df_msg['is_from_me'] == 1])\n",
    "by_himher = total - by_me\n",
    "print('Total: ' + str(total))\n",
    "print('From me: ' + str(by_me))\n",
    "print('From him/her: ' + str(by_himher))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frequencies = {}\n",
    "for message in df_msg['text']:\n",
    "    if message != None:\n",
    "        words = message.split(\" \")\n",
    "        for word in words:\n",
    "            word = re.sub(r'[^\\w\\s]','', word).lower().strip()\n",
    "            if word not in stopwords and word != '':\n",
    "                if word in frequencies:\n",
    "                    frequencies[word] += 1\n",
    "                else:\n",
    "                    frequencies[word] = 1\n",
    "\n",
    "frequencies_sorted = sorted(frequencies.items(), key=lambda kv: kv[1])\n",
    "print(frequencies_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most active day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_active_day = df_msg['new_date'].mode()[0]\n",
    "most_active_day.strftime('%m.%d.%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of texts on that day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_on_the_most_active_day = df_msg[df_msg['new_date'] == most_active_day]\n",
    "num_of_texts = len(df_on_the_most_active_day)\n",
    "num_of_texts_from_me = len(df_on_the_most_active_day[df_on_the_most_active_day['is_from_me'] == 1])\n",
    "num_of_texts_from_them = num_of_texts - num_of_texts_from_me\n",
    "\n",
    "print('Total texts sent on ' + str(most_common_day) + ' was ' + str(num_of_texts))\n",
    "print('From me: ' + str(num_of_texts_from_me))\n",
    "print('From him/her: ' + str(num_of_texts_from_them))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average messages per day that we texted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages_total = 0;\n",
    "distinct_days = 0;\n",
    "last_day_tracked = None;\n",
    "\n",
    "for index, row in df_msg.iterrows():\n",
    "    message = row['text']\n",
    "    if message != None:\n",
    "        messages_total += 1\n",
    "        current_day = row['new_date']\n",
    "        if last_day_tracked != current_day: \n",
    "            distinct_days += 1\n",
    "        last_day_tracked = current_day\n",
    "            \n",
    "print('Sent ' + str(math.floor(messages_total / distinct_days)) + ' messages on average each day.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create radar/spider plot showing average daily activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Format data frames\n",
    "\n",
    "df_24hrs_me = df_msg[df_msg['is_from_me'] == 1]['new_hours']\n",
    "df_24hrs_himher = df_msg[df_msg['is_from_me'] == 0]['new_hours']\n",
    "values_me = df_24hrs_me.value_counts().sort_index().values.flatten().tolist() # IMPORTANT TO SORT HOURS\n",
    "values_himher = df_24hrs_himher.value_counts().sort_index().values.flatten().tolist() # IMPORTANT TO SORT HOURS\n",
    "\n",
    "# We need to repeat the first value to close the circular graph:\n",
    "values_me += values_me[:1]\n",
    "values_himher += values_himher[:1]\n",
    "\n",
    "# Get number of variables\n",
    "categories = set(list(df_msg['new_hours'])[1:]) # set() reduces to distinct values\n",
    "N = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set angle of each axis in the plot (again repeating first value to close the circular graph)\n",
    "angles = [n / float(N) * 2 * math.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Initialize spider plot\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "## If you want the first axis to be on top\n",
    "ax.set_theta_offset(math.pi/2)\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "# Draw one axe per variable + add labels \n",
    "plt.xticks(angles[:-1], categories, color='grey', size=8);\n",
    "\n",
    "# Draw ylabels\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks([1000,2000,3000,4000,5000,6000], [\"1k\", \"2k\", \"3k\",\"4k\",\"5k\",\"6k\"], color='grey', size=8)\n",
    "plt.ylim(0,max(values_me))\n",
    "\n",
    "## ----------- Plot Individual 1 :: me\n",
    "ax.plot(angles, values_me, linewidth=1, linestyle='solid')\n",
    "ax.fill(angles, values_me, 'b', alpha=0.1);\n",
    " \n",
    "## ----------- Plot Individual 2 :: himher\n",
    "ax.plot(angles, values_himher, linewidth=1, linestyle='solid')\n",
    "ax.fill(angles, values_himher, 'r', alpha=0.1)\n",
    "\n",
    "red_patch = mpatches.Patch(color='r', label='Him',alpha=0.1)\n",
    "blue_patch = mpatches.Patch(color='b', label='Me',alpha=0.1)\n",
    "plt.legend(handles=[red_patch, blue_patch],loc='upper right', bbox_to_anchor=(0.1,0.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First occurrence of \"I love you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_msg[df_msg['text'].str.contains('i love you', case=False) == True].sort_values(by='time').head(10)\n",
    "\n",
    "\n",
    "# idxmax shows first index value by condition, only necessitates that index is unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative query to avoid cases like \"I love your wordplay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "love_tests = pd.Series(['I love you', 'I love your wordplay']) # I don't really have other instances rn\n",
    "love_tests.str.contains(r'i love you\\b.*', case=False)\n",
    "ilys = df_msg[df_msg['text'].str.contains(r'i love you\\b.*', case=False) == True].sort_values(by='time')\n",
    "print('Said \"I love you\" ' + str(len(ilys)) + ' times')\n",
    "ilys.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The actual texts:\n",
    "print(df_msg.iloc[54171].text)\n",
    "print(df_msg.iloc[54172].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages_week = df_msg.set_index('time').resample('W-MON')['text'].count()\n",
    "print(messages_week[50:100])\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 10)\n",
    "plt.plot(messages_week, label='messages', color='pink') # the 200 is where on y axis the arrow points to\n",
    "\n",
    "fig.suptitle('Weekly message overview', fontsize=20)\n",
    "plt.xlabel('Weeks', fontsize=18)\n",
    "plt.ylabel('Messages', fontsize=18)\n",
    "plt.annotate('Ireland', (mdates.date2num(datetime.datetime(2018, 3, 15)), 200), xytext=(-100,0), \n",
    "            textcoords='offset points', size=20,\n",
    "            va='center', ha='center',\n",
    "            arrowprops=dict(arrowstyle=\"->\",\n",
    "                           connectionstyle='arc3, rad=-0.2',\n",
    "                           lw=2),\n",
    "            )\n",
    "plt.annotate('Bri in DC', (mdates.date2num(datetime.datetime(2018, 8, 28)), 205), xytext=(50, -50),\n",
    "            textcoords='offset points', size=20,\n",
    "            va='center', ha='center',\n",
    "            arrowprops=dict(arrowstyle=\"->\", lw=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same analysis as above but with heat map (BROKEN RN) \n",
    "http://nbviewer.jupyter.org/github/home-assistant/home-assistant-notebooks/blob/master/DataExploration-2/DataExploration-2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build data frame for heatmap. This data frame contains dates, days of the week, and frequency of texts on that day. \n",
    "\n",
    "# Need to populate missing dates with zeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we weren't using calmap, a way would be to use seaborn to make a calendar heatmap table. The dataframe needs to have rows that represent that week in the year (from 1 - 52), and columns that represent each day of the week. The values are how many texts were sent that day.\n",
    "\n",
    "Can hover over squares to find date?\n",
    "\n",
    "Calmap does this for us.\n",
    "https://pythonhosted.org/calmap/\n",
    "\n",
    "https://pythonhosted.org/calmap/_modules/calmap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get message counts for each day \n",
    "msg_counts = df_msg.set_index('time').resample('D')['text'].count()\n",
    "heatmap_df = pd.DataFrame({'date': msg_counts.index, 'count': msg_counts.values})\n",
    "\n",
    "# Assign each day with Monday, Tuesday, Wednesday, etc\n",
    "def label_day(date):\n",
    "    day_of_week = date.weekday()\n",
    "    switcher = {\n",
    "        0: \"Monday\",\n",
    "        1: \"Tuesday\",\n",
    "        2: \"Wednesday\",\n",
    "        3: \"Thursday\",\n",
    "        4: \"Friday\",\n",
    "        5: \"Saturday\",\n",
    "        6: \"Sunday\"\n",
    "    }\n",
    "    return switcher.get(day_of_week)\n",
    "\n",
    "heatmap_df['day'] = messages_day.index.map(label_day)\n",
    "# Remove dates with 0 activity (we don't want them in the activity comparison)\n",
    "heatmap_df = heatmap_df[heatmap_df['count'] != 0]\n",
    "\n",
    "fig, axes = calmap.calendarplot(\n",
    "    heatmap_df.set_index('date')['count'], \n",
    "    dayticks=[0,2,4,6],\n",
    "    yearlabels = True,\n",
    "    yearascending = False,\n",
    "    how=None\n",
    ")\n",
    "\n",
    "plt.savefig('heatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows who was more predominant in texting that day, not how many text messages were sent that day. The more toward 1, the more it was me. The more toward 0, the more it was him.\n",
    "\n",
    "After subtracting 0.5 (the mean), the positive numbers are me. The negative numbers are him.\n",
    "\n",
    "Note: Stopped working on this. Heatmap is probably not the best way to show this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Shows frequency of messages that are from me or him -- is_from_me compares who spoke the most that day\n",
    "df_activity = df_msg.set_index('time').resample('D')['is_from_me'].mean()\n",
    "df_activity = df_activity[df_activity != 0]\n",
    "df_activity = df_activity.subtract(0.5)\n",
    "print(df_activity)\n",
    "\n",
    "df_activity = df_activity[df_activity != -0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NATURAL LANGUAGE PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/guiem/my_notebooks/blob/master/anniversary/anniversary.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate word cloud (needs stopwords and fixing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullTexts = \"\"\n",
    "for message in df_msg['text']:\n",
    "    if message != None:\n",
    "        fullTexts += message.lower()\n",
    "\n",
    "def generate_wordcloud(text):\n",
    "    wordcloud = WordCloud(font_path = '/Library/Fonts/Verdana.ttf',\n",
    "                         relative_scaling = 1.0).generate(text)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "generate_wordcloud(fullTexts)\n",
    "\n",
    "df_with_text = df_msg.text_normalized.dropna()\n",
    "top_1000 = pd.Series(' '.join(df_with_text).split()).value_counts()[:1000]\n",
    "wc = WordCloud(background_color='white')\n",
    "wc.generate_from_frequencies(list(top_1000).to_dict().items())\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to respond to a previous message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Emojis**\n",
    "\n",
    "This code captures emojis that are followed by a space. Otherwise I'll need to substitute regexs for every emoji.\n",
    "\n",
    "To get newer emojis if I use OS X Sierra: https://stephenradford.me/install-high-sierra-emoji-on-older-versions/\n",
    "\n",
    "Bugs:\n",
    "- Some emojis have two code points \\u\\u, and those are not recognized...? Such as the red heart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_emojis = pd.DataFrame(columns=['emoji', 'is_from_me'])\n",
    "for index, row in df_msg.iterrows():\n",
    "    message = row['text']\n",
    "    if message: # some messages are None?\n",
    "        for word in message.split(' '):\n",
    "            for char in word:\n",
    "                if char in emoji.UNICODE_EMOJI:\n",
    "                    df_emojis = df_emojis.append({'emoji': char, 'is_from_me': row['is_from_me']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frequent_emojis = Counter(df_emojis['emoji']).most_common(25)\n",
    "frequent_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "# reiterate over df_emojis using each frequent emoji to find numbers of times we each sent it\n",
    "for emoji in frequent_emojis:\n",
    "    # Find all instances of the emoji\n",
    "    instances = df_emojis[df_emojis['emoji'] == emoji[0]]\n",
    "    # Loop over each instance to see who sent it\n",
    "    for index, row in instances.iterrows():\n",
    "        # Get who sent it\n",
    "        who_sent_it = row['is_from_me']\n",
    "        # Update frequencies\n",
    "        if emoji in data:\n",
    "            data[emoji][who_sent_it] += 1\n",
    "        else:\n",
    "            if who_sent_it == 1:\n",
    "                data[emoji] = {0: 0, 1: 1}\n",
    "            else:\n",
    "                data[emoji] = {0: 1, 1: 0}\n",
    "\n",
    "print(data)\n",
    "print()\n",
    "\n",
    "labels = list(zip(*data.keys()))[0]\n",
    "print(labels)\n",
    "print()\n",
    "\n",
    "his_freqs = [item[0] for key, item in data.items()]\n",
    "her_freqs = [item[1] for key, item in data.items()]\n",
    "print(his_freqs)\n",
    "print(her_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as mfm\n",
    "emoji_font = mfm.FontProperties(fname=\"/System/Library/Fonts/Apple Color Emoji.ttc\")\n",
    "\n",
    "N = len(labels)\n",
    "ind = np.arange(N) # x locations for the groups\n",
    "width = 0.8\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = plt.gca()\n",
    "plt.title('Most Frequently Used Emojis')\n",
    "plt.ylabel('Frequency', fontsize=15)\n",
    "plt.xlabel('Emojis', fontsize=15)\n",
    "\n",
    "p1 = plt.bar(ind, his_freqs, width, color=\"lightblue\")\n",
    "p2 = plt.bar(ind, her_freqs, width, bottom=his_freqs, color=\"pink\")\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='x',\n",
    "    which='both',\n",
    "    bottom=False,\n",
    "    top=False,\n",
    "    labelbottom=False\n",
    ")\n",
    "\n",
    "new_ylim = plt.ylim()[1]+30\n",
    "plt.ylim(0, new_ylim)\n",
    "\n",
    "# Make labels\n",
    "for rect1, rect2, label in zip(p1, p2, labels):\n",
    "    height = rect1.get_height() + rect2.get_height()\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        (rect1.get_x() + rect1.get_width()/2, height+5),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=30,\n",
    "        fontproperties=emoji_font\n",
    "    )\n",
    "\n",
    "plt.legend((p1[0], p2[0]), (\"Him\", \"Me\"), fontsize=12, ncol=4, framealpha=0, fancybox=True)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: To Toggle Scrolling go Cell > Current Outputs > Toggle Scrolling. Or click on the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make stacked chart with my usages and his usages stacked.\n",
    "\n",
    "And do this:\n",
    "https://medium.freecodecamp.org/and-the-most-popular-developer-emoji-is-d660a9687be7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import numpy as np\n",
    "\n",
    "prop = FontProperties(fname='/System/Library/Fonts/Apple Color Emoji.ttc')\n",
    "\n",
    "freqs = [301, 96, 53, 81, 42]\n",
    "labels = ['😊', '😱', '😂', '😄', '😛']\n",
    "plt.figure(figsize=(12,8))\n",
    "p1 = plt.bar(np.arange(len(labels)), freqs, 0.8)\n",
    "new_ylim = plt.ylim()[1]+30\n",
    "plt.ylim(0, new_ylim)\n",
    "\n",
    "# Make labels\n",
    "for rect1, label in zip(p1, labels):\n",
    "    height = rect1.get_height()\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        (rect1.get_x() + rect1.get_width()/2, height+5),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize='30',\n",
    "        fontproperties = prop\n",
    "    )\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Emoji frequency word cloud**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emoji_str = df_emojis['emoji'].str.cat(sep=' ')\n",
    "try:\n",
    "    emoji_str.decode('utf-8')\n",
    "    print('is utf8')\n",
    "except UnicodeError:\n",
    "    print('not utf8')\n",
    "wordcloud=WordCloud(font_path=\"/System/Library/Fonts/Apple Color Emoji.ttc\", regexp=r\"(?:[^\\s])\", width=500,height=500,margin=1).generate(emoji_str)\n",
    "plt.imshow(wordcloud,interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find most common abbreviation 'idk' 'smh' 'wtf' 'brb\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

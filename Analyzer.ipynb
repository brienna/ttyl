{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages for entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module://ipykernel.pylab.backend_inline\n",
      "module://mplcairo.macosx\n",
      "1.16.0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3, json, re, datetime, math, emoji, matplotlib\n",
    "print(matplotlib.get_backend())\n",
    "import mplcairo\n",
    "matplotlib.use(\"module://mplcairo.macosx\")\n",
    "print(matplotlib.get_backend())\n",
    "print(mplcairo._mplcairo.__cairo_version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "#from wordcloud import WordCloud\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopwords = json.load(open('stopwords.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Messages database using Sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/Users/Brienna/Library/Messages/chat.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let user identify which handle_id to analyze**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View headings in the Messages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('ROWID', None, None, None, None, None, None),\n",
       " ('guid', None, None, None, None, None, None),\n",
       " ('text', None, None, None, None, None, None),\n",
       " ('replace', None, None, None, None, None, None),\n",
       " ('service_center', None, None, None, None, None, None),\n",
       " ('handle_id', None, None, None, None, None, None),\n",
       " ('subject', None, None, None, None, None, None),\n",
       " ('country', None, None, None, None, None, None),\n",
       " ('attributedBody', None, None, None, None, None, None),\n",
       " ('version', None, None, None, None, None, None),\n",
       " ('type', None, None, None, None, None, None),\n",
       " ('service', None, None, None, None, None, None),\n",
       " ('account', None, None, None, None, None, None),\n",
       " ('account_guid', None, None, None, None, None, None),\n",
       " ('error', None, None, None, None, None, None),\n",
       " ('date', None, None, None, None, None, None),\n",
       " ('date_read', None, None, None, None, None, None),\n",
       " ('date_delivered', None, None, None, None, None, None),\n",
       " ('is_delivered', None, None, None, None, None, None),\n",
       " ('is_finished', None, None, None, None, None, None),\n",
       " ('is_emote', None, None, None, None, None, None),\n",
       " ('is_from_me', None, None, None, None, None, None),\n",
       " ('is_empty', None, None, None, None, None, None),\n",
       " ('is_delayed', None, None, None, None, None, None),\n",
       " ('is_auto_reply', None, None, None, None, None, None),\n",
       " ('is_prepared', None, None, None, None, None, None),\n",
       " ('is_read', None, None, None, None, None, None),\n",
       " ('is_system_message', None, None, None, None, None, None),\n",
       " ('is_sent', None, None, None, None, None, None),\n",
       " ('has_dd_results', None, None, None, None, None, None),\n",
       " ('is_service_message', None, None, None, None, None, None),\n",
       " ('is_forward', None, None, None, None, None, None),\n",
       " ('was_downgraded', None, None, None, None, None, None),\n",
       " ('is_archive', None, None, None, None, None, None),\n",
       " ('cache_has_attachments', None, None, None, None, None, None),\n",
       " ('cache_roomnames', None, None, None, None, None, None),\n",
       " ('was_data_detected', None, None, None, None, None, None),\n",
       " ('was_deduplicated', None, None, None, None, None, None),\n",
       " ('is_audio_message', None, None, None, None, None, None),\n",
       " ('is_played', None, None, None, None, None, None),\n",
       " ('date_played', None, None, None, None, None, None),\n",
       " ('item_type', None, None, None, None, None, None),\n",
       " ('other_handle', None, None, None, None, None, None),\n",
       " ('group_title', None, None, None, None, None, None),\n",
       " ('group_action_type', None, None, None, None, None, None),\n",
       " ('share_status', None, None, None, None, None, None),\n",
       " ('share_direction', None, None, None, None, None, None),\n",
       " ('is_expirable', None, None, None, None, None, None),\n",
       " ('expire_state', None, None, None, None, None, None),\n",
       " ('message_action_type', None, None, None, None, None, None),\n",
       " ('message_source', None, None, None, None, None, None),\n",
       " ('associated_message_guid', None, None, None, None, None, None),\n",
       " ('balloon_bundle_id', None, None, None, None, None, None),\n",
       " ('payload_data', None, None, None, None, None, None),\n",
       " ('associated_message_type', None, None, None, None, None, None),\n",
       " ('expressive_send_style_id', None, None, None, None, None, None),\n",
       " ('associated_message_range_location', None, None, None, None, None, None),\n",
       " ('associated_message_range_length', None, None, None, None, None, None),\n",
       " ('time_expressive_send_played', None, None, None, None, None, None),\n",
       " ('message_summary_info', None, None, None, None, None, None))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute('select * from message')\n",
    "c.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the rowid, text, is_from_me, and datetime columns, placing into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_from_me</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111318</td>\n",
       "      <td>Howdy üòÅ</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-27 15:38:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111319</td>\n",
       "      <td>Hey there stranger</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-27 15:55:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111320</td>\n",
       "      <td>How's it being back at work after such a long ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-27 15:55:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111323</td>\n",
       "      <td>I took today off too &gt;.&lt; Larry and Anna both a...</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-27 16:37:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111324</td>\n",
       "      <td>I‚Äôll be going in later to rescue cells, though...</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-27 16:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111325</td>\n",
       "      <td>How were the desserts?</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-27 16:38:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111328</td>\n",
       "      <td>Oh damn eh it's just cancer research, no big d...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-27 16:42:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>111330</td>\n",
       "      <td>üòú</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-27 16:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>111334</td>\n",
       "      <td>We have a limited supply of pellets which will...</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-27 16:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>111335</td>\n",
       "      <td>A pellet = one flask of cells spun down in a c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-27 16:45:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>111340</td>\n",
       "      <td>Instead I get to read about the wonderful inne...</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-27 16:47:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>111349</td>\n",
       "      <td>Ooh that sounds stimulating! I'm on the way to...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-27 16:48:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>111350</td>\n",
       "      <td>Yeah! I‚Äôll be heading back up into Maryland ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-27 17:09:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>111351</td>\n",
       "      <td>So let‚Äôs meet at Earth Treks at ~6pm?</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-27 17:10:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>111352</td>\n",
       "      <td>It's a plan, Stan</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-27 17:10:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>111355</td>\n",
       "      <td>I remember you mentioned wtp were having an ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-28 21:49:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>111356</td>\n",
       "      <td>Let's see if we can't get a table?</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-28 21:49:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>111357</td>\n",
       "      <td>? You have work &amp; it's a social</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-28 21:49:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>111358</td>\n",
       "      <td>Oh oh</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-28 21:49:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>111359</td>\n",
       "      <td>I meant for BRABO</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-28 21:49:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>111360</td>\n",
       "      <td>That üòä</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-28 21:51:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>111361</td>\n",
       "      <td>Blonde moment qq</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-28 21:51:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>111362</td>\n",
       "      <td>Not quite blonde</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-28 21:51:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>111363</td>\n",
       "      <td>Dirty blonde moment</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-28 21:51:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>111364</td>\n",
       "      <td>But sure</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-28 21:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>111371</td>\n",
       "      <td>Currently at Van Ness</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-27 22:09:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>111373</td>\n",
       "      <td>Whoa why</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-27 22:17:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>111374</td>\n",
       "      <td>I just got to Grosvenor, meet me here? I have ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-27 22:17:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>111384</td>\n",
       "      <td>Where you at</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-27 22:19:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>111390</td>\n",
       "      <td>üòÑüëç</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-29 00:02:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115873</th>\n",
       "      <td>394658</td>\n",
       "      <td>So Winterfell will be taken care of until I ge...</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 18:44:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115874</th>\n",
       "      <td>394659</td>\n",
       "      <td>Thank</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 18:44:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115875</th>\n",
       "      <td>394660</td>\n",
       "      <td>Of course babe of course</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 18:44:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115876</th>\n",
       "      <td>394663</td>\n",
       "      <td>Good riddance to the old showerhead!</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 18:53:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115877</th>\n",
       "      <td>394664</td>\n",
       "      <td>Hopefully it doesn‚Äôt go four years before bein...</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 18:54:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115878</th>\n",
       "      <td>394665</td>\n",
       "      <td>Proud of you</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 19:01:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115879</th>\n",
       "      <td>394666</td>\n",
       "      <td>How are you</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 19:07:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115880</th>\n",
       "      <td>394667</td>\n",
       "      <td>At target</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 19:08:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115881</th>\n",
       "      <td>394668</td>\n",
       "      <td>Making returns &amp; getting essentials like toile...</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 19:08:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115882</th>\n",
       "      <td>394669</td>\n",
       "      <td>They must know you by sight at the return desk...</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 19:09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115883</th>\n",
       "      <td>394670</td>\n",
       "      <td>Whatcha bringing back?</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 19:09:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115884</th>\n",
       "      <td>394671</td>\n",
       "      <td>Ah, your annual TP purchase?</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 19:09:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115885</th>\n",
       "      <td>394677</td>\n",
       "      <td>Hey i‚Äôm thinking of drivin down today</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 19:13:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115886</th>\n",
       "      <td>394707</td>\n",
       "      <td>I should have last week so i could spend today...</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 19:21:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115887</th>\n",
       "      <td>394708</td>\n",
       "      <td>But we‚Äôll have tomorrow?</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 19:21:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115888</th>\n",
       "      <td>394709</td>\n",
       "      <td>And thanksgiving?</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 19:21:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115889</th>\n",
       "      <td>394710</td>\n",
       "      <td>Im going home to pack</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 19:22:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115890</th>\n",
       "      <td>394711</td>\n",
       "      <td>Lmk</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 19:22:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115891</th>\n",
       "      <td>394713</td>\n",
       "      <td>I would love that!</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 19:23:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115892</th>\n",
       "      <td>394714</td>\n",
       "      <td>Can you be here already!!!</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 19:23:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115893</th>\n",
       "      <td>394715</td>\n",
       "      <td>Ok!</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 19:24:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115894</th>\n",
       "      <td>394716</td>\n",
       "      <td>What should I get from the store today</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 19:25:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115895</th>\n",
       "      <td>394717</td>\n",
       "      <td>I have a trout filet I can cook for us tonight...</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 19:25:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115896</th>\n",
       "      <td>394718</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 19:25:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115897</th>\n",
       "      <td>394719</td>\n",
       "      <td>Ill bring some food</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 19:25:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115898</th>\n",
       "      <td>394720</td>\n",
       "      <td>I‚Äôll also look for a turkey</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 19:25:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115899</th>\n",
       "      <td>394721</td>\n",
       "      <td>My first turkey! üôÄ</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 19:25:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115900</th>\n",
       "      <td>394722</td>\n",
       "      <td>What should I bring?</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 19:27:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115901</th>\n",
       "      <td>394723</td>\n",
       "      <td>I wish I had driven down yesterday</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19 19:27:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115902</th>\n",
       "      <td>394725</td>\n",
       "      <td>Whatever you want! And yourself! And the cat!</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-19 19:29:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115903 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text  is_from_me  \\\n",
       "0       111318                                            Howdy üòÅ           0   \n",
       "1       111319                                 Hey there stranger           1   \n",
       "2       111320  How's it being back at work after such a long ...           0   \n",
       "3       111323  I took today off too >.< Larry and Anna both a...           1   \n",
       "4       111324  I‚Äôll be going in later to rescue cells, though...           1   \n",
       "5       111325                             How were the desserts?           1   \n",
       "6       111328  Oh damn eh it's just cancer research, no big d...           0   \n",
       "7       111330                                                  üòú           1   \n",
       "8       111334  We have a limited supply of pellets which will...           1   \n",
       "9       111335  A pellet = one flask of cells spun down in a c...           1   \n",
       "10      111340  Instead I get to read about the wonderful inne...           1   \n",
       "11      111349  Ooh that sounds stimulating! I'm on the way to...           0   \n",
       "12      111350  Yeah! I‚Äôll be heading back up into Maryland ar...           1   \n",
       "13      111351              So let‚Äôs meet at Earth Treks at ~6pm?           1   \n",
       "14      111352                                  It's a plan, Stan           0   \n",
       "15      111355  I remember you mentioned wtp were having an ev...           0   \n",
       "16      111356                 Let's see if we can't get a table?           0   \n",
       "17      111357                    ? You have work & it's a social           1   \n",
       "18      111358                                              Oh oh           1   \n",
       "19      111359                                  I meant for BRABO           0   \n",
       "20      111360                                             That üòä           0   \n",
       "21      111361                                   Blonde moment qq           0   \n",
       "22      111362                                   Not quite blonde           1   \n",
       "23      111363                                Dirty blonde moment           1   \n",
       "24      111364                                           But sure           1   \n",
       "25      111371                              Currently at Van Ness           0   \n",
       "26      111373                                           Whoa why           1   \n",
       "27      111374  I just got to Grosvenor, meet me here? I have ...           1   \n",
       "28      111384                                       Where you at           1   \n",
       "29      111390                                                 üòÑüëç           0   \n",
       "...        ...                                                ...         ...   \n",
       "115873  394658  So Winterfell will be taken care of until I ge...           0   \n",
       "115874  394659                                             Thank            1   \n",
       "115875  394660                           Of course babe of course           0   \n",
       "115876  394663               Good riddance to the old showerhead!           0   \n",
       "115877  394664  Hopefully it doesn‚Äôt go four years before bein...           0   \n",
       "115878  394665                                       Proud of you           1   \n",
       "115879  394666                                        How are you           0   \n",
       "115880  394667                                          At target           1   \n",
       "115881  394668  Making returns & getting essentials like toile...           1   \n",
       "115882  394669  They must know you by sight at the return desk...           0   \n",
       "115883  394670                             Whatcha bringing back?           0   \n",
       "115884  394671                       Ah, your annual TP purchase?           0   \n",
       "115885  394677              Hey i‚Äôm thinking of drivin down today           1   \n",
       "115886  394707  I should have last week so i could spend today...           1   \n",
       "115887  394708                           But we‚Äôll have tomorrow?           1   \n",
       "115888  394709                                  And thanksgiving?           1   \n",
       "115889  394710                             Im going home to pack            1   \n",
       "115890  394711                                                Lmk           1   \n",
       "115891  394713                                 I would love that!           0   \n",
       "115892  394714                         Can you be here already!!!           0   \n",
       "115893  394715                                                Ok!           1   \n",
       "115894  394716             What should I get from the store today           0   \n",
       "115895  394717  I have a trout filet I can cook for us tonight...           0   \n",
       "115896  394718                                            Perfect           1   \n",
       "115897  394719                                Ill bring some food           1   \n",
       "115898  394720                       I‚Äôll also look for a turkey            0   \n",
       "115899  394721                                 My first turkey! üôÄ           0   \n",
       "115900  394722                               What should I bring?           1   \n",
       "115901  394723                 I wish I had driven down yesterday           1   \n",
       "115902  394725      Whatever you want! And yourself! And the cat!           0   \n",
       "\n",
       "                       time  \n",
       "0       2016-01-27 15:38:40  \n",
       "1       2016-01-27 15:55:44  \n",
       "2       2016-01-27 15:55:44  \n",
       "3       2016-01-27 16:37:25  \n",
       "4       2016-01-27 16:37:48  \n",
       "5       2016-01-27 16:38:05  \n",
       "6       2016-01-27 16:42:40  \n",
       "7       2016-01-27 16:43:09  \n",
       "8       2016-01-27 16:44:36  \n",
       "9       2016-01-27 16:45:32  \n",
       "10      2016-01-27 16:47:19  \n",
       "11      2016-01-27 16:48:52  \n",
       "12      2016-01-27 17:09:09  \n",
       "13      2016-01-27 17:10:20  \n",
       "14      2016-01-27 17:10:24  \n",
       "15      2016-01-28 21:49:52  \n",
       "16      2016-01-28 21:49:52  \n",
       "17      2016-01-28 21:49:52  \n",
       "18      2016-01-28 21:49:52  \n",
       "19      2016-01-28 21:49:52  \n",
       "20      2016-01-28 21:51:29  \n",
       "21      2016-01-28 21:51:33  \n",
       "22      2016-01-28 21:51:44  \n",
       "23      2016-01-28 21:51:55  \n",
       "24      2016-01-28 21:52:00  \n",
       "25      2016-01-27 22:09:04  \n",
       "26      2016-01-27 22:17:36  \n",
       "27      2016-01-27 22:17:36  \n",
       "28      2016-01-27 22:19:44  \n",
       "29      2016-01-29 00:02:08  \n",
       "...                     ...  \n",
       "115873  2018-11-19 18:44:40  \n",
       "115874  2018-11-19 18:44:46  \n",
       "115875  2018-11-19 18:44:55  \n",
       "115876  2018-11-19 18:53:57  \n",
       "115877  2018-11-19 18:54:34  \n",
       "115878  2018-11-19 19:01:26  \n",
       "115879  2018-11-19 19:07:12  \n",
       "115880  2018-11-19 19:08:10  \n",
       "115881  2018-11-19 19:08:20  \n",
       "115882  2018-11-19 19:09:11  \n",
       "115883  2018-11-19 19:09:15  \n",
       "115884  2018-11-19 19:09:23  \n",
       "115885  2018-11-19 19:13:48  \n",
       "115886  2018-11-19 19:21:23  \n",
       "115887  2018-11-19 19:21:28  \n",
       "115888  2018-11-19 19:21:41  \n",
       "115889  2018-11-19 19:22:15  \n",
       "115890  2018-11-19 19:22:16  \n",
       "115891  2018-11-19 19:23:20  \n",
       "115892  2018-11-19 19:23:55  \n",
       "115893  2018-11-19 19:24:02  \n",
       "115894  2018-11-19 19:25:06  \n",
       "115895  2018-11-19 19:25:26  \n",
       "115896  2018-11-19 19:25:35  \n",
       "115897  2018-11-19 19:25:39  \n",
       "115898  2018-11-19 19:25:50  \n",
       "115899  2018-11-19 19:25:59  \n",
       "115900  2018-11-19 19:27:01  \n",
       "115901  2018-11-19 19:27:12  \n",
       "115902  2018-11-19 19:29:37  \n",
       "\n",
       "[115903 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd1 = 'SELECT ROWID, text, is_from_me, \\\n",
    "        datetime(date + strftime(\\'%s\\',\\'2001-01-01\\'), \\'unixepoch\\') as date_utc \\\n",
    "        FROM message WHERE handle_id=47'\n",
    "c.execute(cmd1)\n",
    "df_msg = pd.DataFrame(c.fetchall(), columns=['id', 'text', 'is_from_me', 'time'])\n",
    "df_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert datatime to something useable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_msg['time'] = [datetime.datetime.strptime(str(t), '%Y-%m-%d %H:%M:%S') + datetime.timedelta(hours=-4) for t in df_msg['time']]\n",
    "df_msg['new_date'] = [d.date() for d in df_msg['time']]\n",
    "df_msg['new_time'] = [d.time() for d in df_msg['time']]\n",
    "df_msg['new_hours'] = [d.hour for d in df_msg['time']]\n",
    "df_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long the conversation has been going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = df_msg['new_date'].iloc[0]\n",
    "end = df_msg['new_date'].iloc[-1]\n",
    "print('from ' + str(start) + ' until ' + str(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total messages sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total = len(df_msg)\n",
    "by_me = len(df_msg[df_msg['is_from_me'] == 1])\n",
    "by_himher = total - by_me\n",
    "print('Total: ' + str(total))\n",
    "print('From me: ' + str(by_me))\n",
    "print('From him/her: ' + str(by_himher))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frequencies = {}\n",
    "for message in df_msg['text']:\n",
    "    if message != None:\n",
    "        words = message.split(\" \")\n",
    "        for word in words:\n",
    "            word = re.sub(r'[^\\w\\s]','', word).lower().strip()\n",
    "            if word not in stopwords and word != '':\n",
    "                if word in frequencies:\n",
    "                    frequencies[word] += 1\n",
    "                else:\n",
    "                    frequencies[word] = 1\n",
    "\n",
    "frequencies_sorted = sorted(frequencies.items(), key=lambda kv: kv[1])\n",
    "print(frequencies_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most active day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mostCommon(lst):\n",
    "    data = Counter(lst)\n",
    "    return max(lst, key=data.get)\n",
    "\n",
    "most_common_day = mostCommon(list(df_msg['new_date']))\n",
    "print(most_common_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of texts on that day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_on_the_most_active_day = df_msg[df_msg['new_date'] == most_common_day]\n",
    "num_of_texts = len(df_on_the_most_active_day)\n",
    "num_of_texts_from_me = len(df_on_the_most_active_day[df_msg['is_from_me'] == 1])\n",
    "num_of_texts_from_himher = num_of_texts - num_of_texts_from_me\n",
    "\n",
    "print('Total texts sent on ' + str(most_common_day) + ' was ' + str(num_of_texts))\n",
    "print('From me: ' + str(num_of_texts_from_me))\n",
    "print('From him/her: ' + str(num_of_texts_from_himher))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average messages per day that we texted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages_total = 0;\n",
    "distinct_days = 0;\n",
    "last_day_tracked = None;\n",
    "\n",
    "for index, row in df_msg.iterrows():\n",
    "    message = row['text']\n",
    "    if message != None:\n",
    "        messages_total += 1\n",
    "        current_day = row['new_date']\n",
    "        if last_day_tracked != current_day: \n",
    "            distinct_days += 1\n",
    "        last_day_tracked = current_day\n",
    "            \n",
    "print('Sent ' + str(math.floor(messages_total / distinct_days)) + ' messages on average each day.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create radar/spider plot showing average daily activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Format data frames\n",
    "\n",
    "df_24hrs_me = df_msg[df_msg['is_from_me'] == 1]['new_hours']\n",
    "df_24hrs_himher = df_msg[df_msg['is_from_me'] == 0]['new_hours']\n",
    "values_me = df_24hrs_me.value_counts().sort_index().values.flatten().tolist() # IMPORTANT TO SORT HOURS\n",
    "values_himher = df_24hrs_himher.value_counts().sort_index().values.flatten().tolist() # IMPORTANT TO SORT HOURS\n",
    "\n",
    "# We need to repeat the first value to close the circular graph:\n",
    "values_me += values_me[:1]\n",
    "values_himher += values_himher[:1]\n",
    "\n",
    "# Get number of variables\n",
    "categories = set(list(df_msg['new_hours'])[1:]) # set() reduces to distinct values\n",
    "N = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set angle of each axis in the plot (again repeating first value to close the circular graph)\n",
    "angles = [n / float(N) * 2 * math.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Initialize spider plot\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "## If you want the first axis to be on top\n",
    "ax.set_theta_offset(math.pi/2)\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "# Draw one axe per variable + add labels \n",
    "plt.xticks(angles[:-1], categories, color='grey', size=8);\n",
    "\n",
    "# Draw ylabels\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks([1000,2000,3000,4000,5000,6000], [\"1k\", \"2k\", \"3k\",\"4k\",\"5k\",\"6k\"], color='grey', size=8)\n",
    "plt.ylim(0,max(values_me))\n",
    "\n",
    "## ----------- Plot Individual 1 :: me\n",
    "ax.plot(angles, values_me, linewidth=1, linestyle='solid')\n",
    "ax.fill(angles, values_me, 'b', alpha=0.1);\n",
    " \n",
    "## ----------- Plot Individual 2 :: himher\n",
    "ax.plot(angles, values_himher, linewidth=1, linestyle='solid')\n",
    "ax.fill(angles, values_himher, 'r', alpha=0.1)\n",
    "\n",
    "red_patch = mpatches.Patch(color='r', label='Him',alpha=0.1)\n",
    "blue_patch = mpatches.Patch(color='b', label='Me',alpha=0.1)\n",
    "plt.legend(handles=[red_patch, blue_patch],loc='upper right', bbox_to_anchor=(0.1,0.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First occurrence of \"I love you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_msg[df_msg['text'].str.contains('i love you', case=False) == True].sort_values(by='time').head(10)\n",
    "\n",
    "\n",
    "# idxmax shows first index value by condition, only necessitates that index is unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative query to avoid cases like \"I love your wordplay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "love_tests = pd.Series(['I love you', 'I love your wordplay']) # I don't really have other instances rn\n",
    "love_tests.str.contains(r'i love you\\b.*', case=False)\n",
    "ilys = df_msg[df_msg['text'].str.contains(r'i love you\\b.*', case=False) == True].sort_values(by='time')\n",
    "print('Said \"I love you\" ' + str(len(ilys)) + ' times')\n",
    "ilys.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The actual texts:\n",
    "print(df_msg.iloc[54171].text)\n",
    "print(df_msg.iloc[54172].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "messages_week = df_msg.groupby(pd.Grouper(key='time', freq='W-MON')).count()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 10)\n",
    "plt.plot(messages_week.text, label='messages', color='pink') # the 200 is where on y axis the arrow points to\n",
    "\n",
    "fig.suptitle('Weekly message overview', fontsize=20)\n",
    "plt.xlabel('Weeks', fontsize=18)\n",
    "plt.ylabel('Messages', fontsize=18)\n",
    "plt.annotate('Ireland', (mdates.date2num(datetime.datetime(2018, 3, 15)), 200), xytext=(-100,0), \n",
    "            textcoords='offset points', size=20,\n",
    "            va='center', ha='center',\n",
    "            arrowprops=dict(arrowstyle=\"->\",\n",
    "                           connectionstyle='arc3, rad=-0.2',\n",
    "                           lw=2),\n",
    "            )\n",
    "plt.annotate('Bri in DC', (mdates.date2num(datetime.datetime(2018, 8, 28)), 205), xytext=(50, -50),\n",
    "            textcoords='offset points', size=20,\n",
    "            va='center', ha='center',\n",
    "            arrowprops=dict(arrowstyle=\"->\", lw=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same analysis as above but with heat map (BROKEN RN) \n",
    "http://nbviewer.jupyter.org/github/home-assistant/home-assistant-notebooks/blob/master/DataExploration-2/DataExploration-2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build data frame for heatmap. This data frame contains dates, days of the week, and frequency of texts on that day. \n",
    "\n",
    "# Need to populate missing dates with zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get dates column\n",
    "dates = df_msg['new_date']\n",
    "# Set counter for dates column  \n",
    "counter = Counter(dates)\n",
    "# Access number of texts on certain date \n",
    "print(counter.get(datetime.date(2016,7,9)))\n",
    "print()\n",
    "\n",
    "def label_day(date):\n",
    "    day_of_week = date.weekday()\n",
    "    switcher = {\n",
    "        0: \"Monday\",\n",
    "        1: \"Tuesday\",\n",
    "        2: \"Wednesday\",\n",
    "        3: \"Thursday\",\n",
    "        4: \"Friday\",\n",
    "        5: \"Saturday\",\n",
    "        6: \"Sunday\"\n",
    "    }\n",
    "    return switcher.get(day_of_week)\n",
    "\n",
    "\n",
    "\n",
    "df_calendar = pd.DataFrame.from_dict(counter, orient='index').reset_index()\n",
    "df_calendar = df_calendar.rename(columns={'index':'date', 0:'frequency'})\n",
    "# Axis 1 is for processing by rows\n",
    "df_calendar['day_of_week'] = df_calendar.apply(lambda row: label_day(row['date']), axis=1)\n",
    "print(df_calendar)\n",
    "num_years = set(list(df_calendar['date'])[1:])\n",
    "\n",
    "# Split data frame into separate data frame for each year\n",
    "year2016 =  pd.date_range('2016/01/01','2016/12/31',freq='H')\n",
    "dt = datetime.datetime(2016,1,3)\n",
    "rows = df_calendar.apply(lambda row: row['date'].year == dt.year, axis=1)\n",
    "year2016data = df_calendar[rows]\n",
    "\n",
    "\n",
    "print(df_calendar)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(50,3)) \n",
    "data = df_calendar.pivot(\"day_of_week\", \"date\", \"frequency\")\n",
    "#ax = sns.heatmap(data)\n",
    "\n",
    "year2016datapivoted = year2016data.pivot(\"day_of_week\", \"date\", \"frequency\")\n",
    "ax = sns.heatmap(year2016datapivoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if _matplotlib_version >= '1.5':\n",
    "    axisbgc = ax.get_facecolor()\n",
    "else:\n",
    "    axisbgc = ax.get_axis_bgcolor()\n",
    "\n",
    "all_days = pd.date_range('1/15/2014', periods=700, freq='D')\n",
    "days = np.random.choice(all_days, 500)\n",
    "events = pd.Series(np.random.randn(len(days)), index=days)\n",
    "calmap.yearplot(events, year=2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NATURAL LANGUAGE PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/guiem/my_notebooks/blob/master/anniversary/anniversary.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate word cloud (needs stopwords and fixing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullTexts = \"\"\n",
    "for message in df_msg['text']:\n",
    "    if message != None:\n",
    "        fullTexts += message.lower()\n",
    "\n",
    "def generate_wordcloud(text):\n",
    "    wordcloud = WordCloud(font_path = '/Library/Fonts/Verdana.ttf',\n",
    "                         relative_scaling = 1.0).generate(text)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "generate_wordcloud(fullTexts)\n",
    "\n",
    "df_with_text = df_msg.text_normalized.dropna()\n",
    "top_1000 = pd.Series(' '.join(df_with_text).split()).value_counts()[:1000]\n",
    "wc = WordCloud(background_color='white')\n",
    "wc.generate_from_frequencies(list(top_1000).to_dict().items())\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to respond to a previous message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Emojis**\n",
    "\n",
    "This code captures emojis that are followed by a space. Otherwise I'll need to substitute regexs for every emoji.\n",
    "\n",
    "To get newer emojis if I use OS X Sierra: https://stephenradford.me/install-high-sierra-emoji-on-older-versions/\n",
    "\n",
    "Bugs:\n",
    "- Some emojis have two code points \\u\\u, and those are not recognized...? Such as the red heart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_emojis = pd.DataFrame(columns=['emoji', 'is_from_me'])\n",
    "for index, row in df_msg.iterrows():\n",
    "    message = row['text']\n",
    "    if message: # some messages are None?\n",
    "        for word in message.split(' '):\n",
    "            for char in word:\n",
    "                if char in emoji.UNICODE_EMOJI:\n",
    "                    df_emojis = df_emojis.append({'emoji': char, 'is_from_me': row['is_from_me']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>is_from_me</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üòÅ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üòú</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üòú</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üòä</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÑ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>üëç</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>üòä</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>üò™</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>üòã</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>üí¶</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>üò©</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>üí¶</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>üòä</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>üòÅ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>üòä</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>üòä</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>üòÅ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ü§ì</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>üòä</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>üòÅ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>üòä</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>üòÑ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>üòÅ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>üòÑ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>üòõ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>üôÇ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>üòä</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>üòä</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>üéÇ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>üéÇ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>üåÄ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>üîû</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>üòÖ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>üòç</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>üòà</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>üòí</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>üëç</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>üçÄ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>üòü</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>üòõ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>üòä</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>üòä</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>üòπ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>ü§û</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>ü§û</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>ü§û</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3242</th>\n",
       "      <td>üòä</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>üòâ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>üòç</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>üôà</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>ü§û</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>ü§û</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>ü§£</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>üôÉ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>üòí</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>üòí</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>üòí</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>üôÄ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3256 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     emoji is_from_me\n",
       "0        üòÅ          0\n",
       "1        üòú          0\n",
       "2        üòú          1\n",
       "3        üòä          0\n",
       "4        üòÑ          0\n",
       "5        üëç          0\n",
       "6        üòä          0\n",
       "7        üò™          1\n",
       "8        üòã          1\n",
       "9        üí¶          1\n",
       "10       üò©          1\n",
       "11       üí¶          1\n",
       "12       üòä          0\n",
       "13       üòÅ          0\n",
       "14       üòä          0\n",
       "15       üòä          0\n",
       "16       üòÅ          0\n",
       "17       ü§ì          0\n",
       "18       üòä          0\n",
       "19       üòÅ          0\n",
       "20       üòä          0\n",
       "21       üòÑ          0\n",
       "22       üòÅ          0\n",
       "23       üòÑ          0\n",
       "24       üòõ          0\n",
       "25       üôÇ          1\n",
       "26       üòä          0\n",
       "27       üòä          0\n",
       "28       üéÇ          0\n",
       "29       üéÇ          0\n",
       "...    ...        ...\n",
       "3226     üåÄ          1\n",
       "3227     üîû          1\n",
       "3228     üòÖ          0\n",
       "3229     üòç          1\n",
       "3230     üòà          0\n",
       "3231     üòí          1\n",
       "3232     üëç          1\n",
       "3233     üçÄ          1\n",
       "3234     üòü          1\n",
       "3235     üòõ          1\n",
       "3236     üòä          1\n",
       "3237     üòä          1\n",
       "3238     üòπ          1\n",
       "3239     ü§û          0\n",
       "3240     ü§û          0\n",
       "3241     ü§û          1\n",
       "3242     üòä          0\n",
       "3243     üòâ          0\n",
       "3244     üòç          1\n",
       "3245     üôà          1\n",
       "3246     ü§û          0\n",
       "3247     ü§û          0\n",
       "3248     üòÇ          0\n",
       "3249     üòÇ          0\n",
       "3250     ü§£          0\n",
       "3251     üôÉ          1\n",
       "3252     üòí          1\n",
       "3253     üòí          1\n",
       "3254     üòí          0\n",
       "3255     üôÄ          0\n",
       "\n",
       "[3256 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('üòä', 400),\n",
       " ('‚ù§', 148),\n",
       " ('üòÇ', 131),\n",
       " ('üòÑ', 122),\n",
       " ('üòõ', 105),\n",
       " ('üôÑ', 93),\n",
       " ('üòÅ', 85),\n",
       " ('üôà', 64),\n",
       " ('üò±', 63),\n",
       " ('üòò', 60),\n",
       " ('ü§û', 58),\n",
       " ('üò≠', 55),\n",
       " ('üòú', 54),\n",
       " ('ü§î', 53),\n",
       " ('‚ôÄ', 53),\n",
       " ('üòÖ', 52),\n",
       " ('ü§∑', 52),\n",
       " ('üò©', 50),\n",
       " ('üëç', 48),\n",
       " ('üò¨', 48),\n",
       " ('üòâ', 46),\n",
       " ('üòè', 42),\n",
       " ('üòÉ', 42),\n",
       " ('ü§ó', 42),\n",
       " ('üòí', 40)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_emojis = Counter(df_emojis['emoji']).most_common(25)\n",
    "frequent_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('üòä', 400): {0: 301, 1: 99}, ('‚ù§', 148): {0: 96, 1: 52}, ('üòÇ', 131): {0: 55, 1: 76}, ('üòÑ', 122): {0: 81, 1: 41}, ('üòõ', 105): {0: 42, 1: 63}, ('üôÑ', 93): {0: 31, 1: 62}, ('üòÅ', 85): {0: 58, 1: 27}, ('üôà', 64): {0: 22, 1: 42}, ('üò±', 63): {0: 37, 1: 26}, ('üòò', 60): {0: 14, 1: 46}, ('ü§û', 58): {0: 51, 1: 7}, ('üò≠', 55): {0: 28, 1: 27}, ('üòú', 54): {0: 25, 1: 29}, ('ü§î', 53): {0: 26, 1: 27}, ('‚ôÄ', 53): {0: 1, 1: 52}}\n",
      "\n",
      "('üòä', '‚ù§', 'üòÇ', 'üòÑ', 'üòõ', 'üôÑ', 'üòÅ', 'üôà', 'üò±', 'üòò', 'ü§û', 'üò≠', 'üòú', 'ü§î', '‚ôÄ')\n",
      "\n",
      "[301, 96, 55, 81, 42, 31, 58, 22, 37, 14, 51, 28, 25, 26, 1]\n",
      "[99, 52, 76, 41, 63, 62, 27, 42, 26, 46, 7, 27, 29, 27, 52]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "# reiterate over df_emojis using each frequent emoji to find numbers of times we each sent it\n",
    "for emoji in frequent_emojis:\n",
    "    # Find all instances of the emoji\n",
    "    instances = df_emojis[df_emojis['emoji'] == emoji[0]]\n",
    "    # Loop over each instance to see who sent it\n",
    "    for index, row in instances.iterrows():\n",
    "        # Get who sent it\n",
    "        who_sent_it = row['is_from_me']\n",
    "        # Update frequencies\n",
    "        if emoji in data:\n",
    "            data[emoji][who_sent_it] += 1\n",
    "        else:\n",
    "            if who_sent_it == 1:\n",
    "                data[emoji] = {0: 0, 1: 1}\n",
    "            else:\n",
    "                data[emoji] = {0: 1, 1: 0}\n",
    "\n",
    "print(data)\n",
    "print()\n",
    "\n",
    "labels = list(zip(*data.keys()))[0]\n",
    "print(labels)\n",
    "print()\n",
    "\n",
    "his_freqs = [item[0] for key, item in data.items()]\n",
    "her_freqs = [item[1] for key, item in data.items()]\n",
    "print(his_freqs)\n",
    "print(her_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as mfm\n",
    "emoji_font = mfm.FontProperties(fname=\"/System/Library/Fonts/Apple Color Emoji.ttc\")\n",
    "\n",
    "N = len(labels)\n",
    "ind = np.arange(N) # x locations for the groups\n",
    "width = 0.8\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = plt.gca()\n",
    "plt.title('Most Frequently Used Emojis')\n",
    "plt.ylabel('Frequency', fontsize=15)\n",
    "plt.xlabel('Emojis', fontsize=15)\n",
    "\n",
    "p1 = plt.bar(ind, his_freqs, width, color=\"lightblue\")\n",
    "p2 = plt.bar(ind, her_freqs, width, bottom=his_freqs, color=\"pink\")\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='x',\n",
    "    which='both',\n",
    "    bottom=False,\n",
    "    top=False,\n",
    "    labelbottom=False\n",
    ")\n",
    "\n",
    "new_ylim = plt.ylim()[1]+30\n",
    "plt.ylim(0, new_ylim)\n",
    "\n",
    "# Make labels\n",
    "for rect1, rect2, label in zip(p1, p2, labels):\n",
    "    height = rect1.get_height() + rect2.get_height()\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        (rect1.get_x() + rect1.get_width()/2, height+5),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=30,\n",
    "        fontproperties=emoji_font\n",
    "    )\n",
    "\n",
    "plt.legend((p1[0], p2[0]), (\"Him\", \"Me\"), fontsize=12, ncol=4, framealpha=0, fancybox=True)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: To Toggle Scrolling go Cell > Current Outputs > Toggle Scrolling. Or click on the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make stacked chart with my usages and his usages stacked.\n",
    "\n",
    "And do this:\n",
    "https://medium.freecodecamp.org/and-the-most-popular-developer-emoji-is-d660a9687be7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import numpy as np\n",
    "\n",
    "prop = FontProperties(fname='/System/Library/Fonts/Apple Color Emoji.ttc')\n",
    "\n",
    "freqs = [301, 96, 53, 81, 42]\n",
    "labels = ['üòä', 'üò±', 'üòÇ', 'üòÑ', 'üòõ']\n",
    "plt.figure(figsize=(12,8))\n",
    "p1 = plt.bar(np.arange(len(labels)), freqs, 0.8)\n",
    "new_ylim = plt.ylim()[1]+30\n",
    "plt.ylim(0, new_ylim)\n",
    "\n",
    "# Make labels\n",
    "for rect1, label in zip(p1, labels):\n",
    "    height = rect1.get_height()\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        (rect1.get_x() + rect1.get_width()/2, height+5),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize='30',\n",
    "        fontproperties = prop\n",
    "    )\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
